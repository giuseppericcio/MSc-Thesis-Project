{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling with PyHealth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PyHealth and Try NOTEEVENTS_ICD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Collecting torch==2.0.1 (from torchvision)\n",
      "  Downloading torch-2.0.1-cp310-cp310-win_amd64.whl (172.3 MB)\n",
      "     -------------------------------------- 172.3/172.3 MB 7.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.0.1->torchvision) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.0.1->torchvision) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.0.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.0.1->torchvision) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.0.1->torchvision) (3.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n",
      "Installing collected packages: torch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Accesso negato: 'C:\\\\Users\\\\AR\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\Lib\\\\site-packages\\\\torch\\\\_C.cp310-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.1.1-cp310-cp310-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.0.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2023.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.1.1-cp310-cp310-win_amd64.whl (192.3 MB)\n",
      "   --------------------------------------- 192.3/192.3 MB 10.9 MB/s eta 0:00:00\n",
      "Installing collected packages: torch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Accesso negato: 'C:\\\\Users\\\\AR\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\Lib\\\\site-packages\\\\torch\\\\lib\\\\uv.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch.amp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\AR\\Desktop\\Tirocinio_Tesi\\MSc-Thesis-Project\\modelling_pyhealth.ipynb Cell 5\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/AR/Desktop/Tirocinio_Tesi/MSc-Thesis-Project/modelling_pyhealth.ipynb#Y116sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/AR/Desktop/Tirocinio_Tesi/MSc-Thesis-Project/modelling_pyhealth.ipynb#Y116sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/AR/Desktop/Tirocinio_Tesi/MSc-Thesis-Project/modelling_pyhealth.ipynb#Y116sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39m__version__)\n",
      "File \u001b[1;32mc:\\Users\\AR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py:1324\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m   1321\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnable to find torch_shm_manager at \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m path)\n\u001b[0;32m   1322\u001b[0m     \u001b[39mreturn\u001b[39;00m path\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1324\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mamp\u001b[39;00m \u001b[39mimport\u001b[39;00m autocast\n\u001b[0;32m   1326\u001b[0m \u001b[39m# Initializing the extension shadows the built-in python float / int classes;\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m \u001b[39m# store them for later use by SymInt / SymFloat.\u001b[39;00m\n\u001b[0;32m   1328\u001b[0m py_float \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch.amp'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "print(torch.__version__)\n",
    "\n",
    "# Install required packages.\n",
    "import os\n",
    "os.environ['TORCH'] = torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cpu\n",
      "Looking in links: https://data.pyg.org/whl/torch-${TORCH}.html\n",
      "Requirement already satisfied: torch-scatter in c:\\users\\ar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.1.2)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carica i dati dai file csv\n",
    "noteevents = pd.read_csv('data/NOTEEVENTS_ICD.csv')\n",
    "patients = pd.read_csv('data/PATIENTS.csv')\n",
    "\n",
    "# seleziona i pazienti presenti in NOTEEVENTS_ICD\n",
    "selected_patients = patients[patients['SUBJECT_ID'].isin(noteevents['SUBJECT_ID'].unique())]\n",
    "\n",
    "# salva il risultato in un file csv\n",
    "selected_patients.to_csv('data/PATIENTS_SEL.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.datasets import MIMIC3Dataset\n",
    "\n",
    "dataset = MIMIC3Dataset(\n",
    "    root='data/',\n",
    "    tables=[\"DIAGNOSES_ICD\",\"PROCEDURES_ICD\",\"PRESCRIPTIONS\",\"NOTEEVENTS_ICD\"],\n",
    "    code_mapping={\"NDC\": (\"ATC\", {\"target_kwargs\": {\"level\": 3}})},\n",
    "    #refresh_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics of base dataset (dev=False):\n",
      "\t- Dataset: MIMIC3Dataset\n",
      "\t- Number of patients: 1560\n",
      "\t- Number of visits: 5014\n",
      "\t- Number of visits per patient: 3.2141\n",
      "\t- Number of events per visit in DIAGNOSES_ICD: 11.5987\n",
      "\t- Number of events per visit in PROCEDURES_ICD: 3.8771\n",
      "\t- Number of events per visit in PRESCRIPTIONS: 44.3879\n",
      "\t- Number of events per visit in NOTEEVENTS_ICD: 11.0782\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nStatistics of base dataset (dev=False):\\n\\t- Dataset: MIMIC3Dataset\\n\\t- Number of patients: 1560\\n\\t- Number of visits: 5014\\n\\t- Number of visits per patient: 3.2141\\n\\t- Number of events per visit in DIAGNOSES_ICD: 11.5987\\n\\t- Number of events per visit in PROCEDURES_ICD: 3.8771\\n\\t- Number of events per visit in PRESCRIPTIONS: 44.3879\\n\\t- Number of events per visit in NOTEEVENTS_ICD: 11.0782\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.stat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo open dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get patient dictionary\n",
    "patient_dict = dataset.patients\n",
    "print(list(patient_dict.keys()))\n",
    "print(len(patient_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the \"10\" patient\n",
    "patient = patient_dict[\"25780\"]\n",
    "patient.gender, patient.birth_datetime, patient.ethnicity, patient.death_datetime, patient.visits\n",
    "print(patient.visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the visit list of this patient\n",
    "visit_dict = patient.visits\n",
    "print (list(visit_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first visit\n",
    "visit = visit_dict['120990']\n",
    "visit.encounter_time, visit.available_tables, visit.num_events, visit.event_list_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit.get_code_list(table='NOTEEVENTS_ICD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples for drug_recommendation_mimic3_fn: 100%|██████████| 1560/1560 [00:00<00:00, 22065.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from pyhealth.tasks import drug_recommendation_mimic3_fn\n",
    "from pyhealth.datasets import split_by_patient, get_dataloader\n",
    "\n",
    "mimic3sample = dataset.set_task(task_fn=drug_recommendation_mimic3_fn) # use default task\n",
    "train_ds, val_ds, test_ds = split_by_patient(mimic3sample, [0.6, 0.2, 0.2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics of sample dataset:\n",
      "\t- Dataset: MIMIC3Dataset\n",
      "\t- Task: drug_recommendation_mimic3_fn\n",
      "\t- Number of samples: 2012\n",
      "\t- Number of patients: 906\n",
      "\t- Number of visits: 2012\n",
      "\t- Number of visits per patient: 2.2208\n",
      "\t- conditions:\n",
      "\t\t- Number of conditions per sample: 18.8827\n",
      "\t\t- Number of unique conditions: 2099\n",
      "\t\t- Distribution of conditions (Top-10): [('4019', 1225), ('4280', 1021), ('42731', 783), ('41401', 767), ('5849', 594), ('25000', 537), ('53081', 458), ('5990', 393), ('40391', 389), ('2724', 386)]\n",
      "\t- procedures:\n",
      "\t\t- Number of procedures per sample: 7.0055\n",
      "\t\t- Number of unique procedures: 731\n",
      "\t\t- Distribution of procedures (Top-10): [('3893', 1047), ('9904', 776), ('9604', 529), ('3995', 505), ('966', 484), ('9671', 477), ('3891', 295), ('9672', 292), ('3961', 267), ('9915', 257)]\n",
      "\t- drugs:\n",
      "\t\t- Number of drugs per sample: 24.4841\n",
      "\t\t- Number of unique drugs: 178\n",
      "\t\t- Distribution of drugs (Top-10): [('A02B', 1797), ('B05X', 1792), ('B01A', 1686), ('N02B', 1681), ('A06A', 1564), ('N02A', 1453), ('V06D', 1383), ('C07A', 1334), ('V04C', 1199), ('A12C', 1190)]\n",
      "\t- drugs_hist:\n",
      "\t\t- Number of drugs_hist per sample: 17.2957\n",
      "\t\t- Number of unique drugs_hist: 174\n",
      "\t\t- Distribution of drugs_hist (Top-10): [('A02B', 1320), ('B05X', 1287), ('B01A', 1236), ('N02B', 1189), ('A06A', 1094), ('N02A', 1024), ('V06D', 999), ('C07A', 976), ('V04C', 840), ('A12C', 834)]\n",
      "\t- symptoms:\n",
      "\t\t- Number of symptoms per sample: 27.8588\n",
      "\t\t- Number of unique symptoms: 714\n",
      "\t\t- Distribution of symptoms (Top-10): [('V419', 3386), ('4019', 2372), ('7823', 2242), ('78060', 2124), ('78096', 2113), ('78650', 1390), ('78609', 1027), ('78605', 1020), ('4289', 1005), ('78900', 901)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Statistics of sample dataset:\\n\\t- Dataset: MIMIC3Dataset\\n\\t- Task: drug_recommendation_mimic3_fn\\n\\t- Number of samples: 2012\\n\\t- Number of patients: 906\\n\\t- Number of visits: 2012\\n\\t- Number of visits per patient: 2.2208\\n\\t- conditions:\\n\\t\\t- Number of conditions per sample: 18.8827\\n\\t\\t- Number of unique conditions: 2099\\n\\t\\t- Distribution of conditions (Top-10): [('4019', 1225), ('4280', 1021), ('42731', 783), ('41401', 767), ('5849', 594), ('25000', 537), ('53081', 458), ('5990', 393), ('40391', 389), ('2724', 386)]\\n\\t- procedures:\\n\\t\\t- Number of procedures per sample: 7.0055\\n\\t\\t- Number of unique procedures: 731\\n\\t\\t- Distribution of procedures (Top-10): [('3893', 1047), ('9904', 776), ('9604', 529), ('3995', 505), ('966', 484), ('9671', 477), ('3891', 295), ('9672', 292), ('3961', 267), ('9915', 257)]\\n\\t- drugs:\\n\\t\\t- Number of drugs per sample: 24.4841\\n\\t\\t- Number of unique drugs: 178\\n\\t\\t- Distribution of drugs (Top-10): [('A02B', 1797), ('B05X', 1792), ('B01A', 1686), ('N02B', 1681), ('A06A', 1564), ('N02A', 1453), ('V06D', 1383), ('C07A', 1334), ('V04C', 1199), ('A12C', 1190)]\\n\\t- drugs_hist:\\n\\t\\t- Number of drugs_hist per sample: 17.2957\\n\\t\\t- Number of unique drugs_hist: 174\\n\\t\\t- Distribution of drugs_hist (Top-10): [('A02B', 1320), ('B05X', 1287), ('B01A', 1236), ('N02B', 1189), ('A06A', 1094), ('N02A', 1024), ('V06D', 999), ('C07A', 976), ('V04C', 840), ('A12C', 834)]\\n\\t- symptoms:\\n\\t\\t- Number of symptoms per sample: 27.8588\\n\\t\\t- Number of unique symptoms: 714\\n\\t\\t- Distribution of symptoms (Top-10): [('V419', 3386), ('4019', 2372), ('7823', 2242), ('78060', 2124), ('78096', 2113), ('78650', 1390), ('78609', 1027), ('78605', 1020), ('4289', 1005), ('78900', 901)]\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mimic3sample.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders (torch.data.DataLoader)\n",
    "train_loader = get_dataloader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = get_dataloader(val_ds, batch_size=32, shuffle=False)\n",
    "test_loader = get_dataloader(test_ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1206, 398, 408)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(val_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. Patients: 906\n",
      "Num. Symptoms: 714\n",
      "Dimension of edge index: torch.Size([2, 32116])\n",
      "Final edge indices pointing from patients to symptoms:\n",
      "=================================================\n",
      "tensor([[  0,   0,   0,  ..., 905, 905, 905],\n",
      "        [  0,   1,   2,  ...,  56, 158, 160]])\n",
      "=================================================\n",
      "Num. Patients: 906\n",
      "Num. Diseases: 2099\n",
      "Dimension of edge index: torch.Size([2, 22069])\n",
      "Final edge indices pointing from patients to diseases:\n",
      "=================================================\n",
      "tensor([[  0,   0,   0,  ..., 905, 905, 905],\n",
      "        [  0,   1,   2,  ..., 123, 198,  66]])\n",
      "=================================================\n",
      "Num. Patients: 906\n",
      "Num. Procedures: 731\n",
      "Dimension of edge index: torch.Size([2, 8538])\n",
      "Final edge indices pointing from patients to procedures:\n",
      "=================================================\n",
      "tensor([[  0,   0,   0,  ..., 905, 905, 905],\n",
      "        [  0,   1,   2,  ...,  17,  31,  47]])\n",
      "=================================================\n",
      "Num. Patients: 906\n",
      "Num. Drugs: 178\n",
      "Dimension of edge index: torch.Size([2, 49262])\n",
      "Final edge indices pointing from patients to drugs:\n",
      "=================================================\n",
      "tensor([[  0,   0,   0,  ..., 905, 905, 905],\n",
      "        [  0,   1,   2,  ...,   2,  29,  12]])\n",
      "=================================================\n",
      "Final graph:\n",
      "HeteroData(\n",
      "  patient={ node_id=[906] },\n",
      "  symptom={ node_id=[714] },\n",
      "  disease={ node_id=[2099] },\n",
      "  procedure={ node_id=[731] },\n",
      "  drug={ node_id=[178] },\n",
      "  (patient, presents, symptom)={ edge_index=[2, 32116] },\n",
      "  (patient, has, disease)={ edge_index=[2, 22069] },\n",
      "  (patient, has_treat, procedure)={ edge_index=[2, 8538] },\n",
      "  (patient, has_received, drug)={ edge_index=[2, 49262] },\n",
      "  (symptom, rev_presents, patient)={ edge_index=[2, 32116] },\n",
      "  (disease, rev_has, patient)={ edge_index=[2, 22069] },\n",
      "  (procedure, rev_has_treat, patient)={ edge_index=[2, 8538] },\n",
      "  (drug, rev_has_received, patient)={ edge_index=[2, 49262] }\n",
      ")\n",
      "Training data:\n",
      "==============\n",
      "HeteroData(\n",
      "  patient={ node_id=[906] },\n",
      "  symptom={ node_id=[714] },\n",
      "  disease={ node_id=[2099] },\n",
      "  procedure={ node_id=[731] },\n",
      "  drug={ node_id=[178] },\n",
      "  (patient, presents, symptom)={\n",
      "    edge_index=[2, 22482],\n",
      "    edge_label=[9634],\n",
      "    edge_label_index=[2, 9634],\n",
      "  },\n",
      "  (patient, has, disease)={\n",
      "    edge_index=[2, 15449],\n",
      "    edge_label=[6620],\n",
      "    edge_label_index=[2, 6620],\n",
      "  },\n",
      "  (patient, has_treat, procedure)={\n",
      "    edge_index=[2, 5977],\n",
      "    edge_label=[2561],\n",
      "    edge_label_index=[2, 2561],\n",
      "  },\n",
      "  (patient, has_received, drug)={\n",
      "    edge_index=[2, 34484],\n",
      "    edge_label=[14778],\n",
      "    edge_label_index=[2, 14778],\n",
      "  },\n",
      "  (symptom, rev_presents, patient)={ edge_index=[2, 22482] },\n",
      "  (disease, rev_has, patient)={ edge_index=[2, 15449] },\n",
      "  (procedure, rev_has_treat, patient)={ edge_index=[2, 5977] },\n",
      "  (drug, rev_has_received, patient)={ edge_index=[2, 34484] }\n",
      ")\n",
      "\n",
      "Validation data:\n",
      "================\n",
      "HeteroData(\n",
      "  patient={ node_id=[906] },\n",
      "  symptom={ node_id=[714] },\n",
      "  disease={ node_id=[2099] },\n",
      "  procedure={ node_id=[731] },\n",
      "  drug={ node_id=[178] },\n",
      "  (patient, presents, symptom)={\n",
      "    edge_index=[2, 32116],\n",
      "    edge_label=[0],\n",
      "    edge_label_index=[2, 0],\n",
      "  },\n",
      "  (patient, has, disease)={\n",
      "    edge_index=[2, 22069],\n",
      "    edge_label=[0],\n",
      "    edge_label_index=[2, 0],\n",
      "  },\n",
      "  (patient, has_treat, procedure)={\n",
      "    edge_index=[2, 8538],\n",
      "    edge_label=[0],\n",
      "    edge_label_index=[2, 0],\n",
      "  },\n",
      "  (patient, has_received, drug)={\n",
      "    edge_index=[2, 49262],\n",
      "    edge_label=[0],\n",
      "    edge_label_index=[2, 0],\n",
      "  },\n",
      "  (symptom, rev_presents, patient)={ edge_index=[2, 32116] },\n",
      "  (disease, rev_has, patient)={ edge_index=[2, 22069] },\n",
      "  (procedure, rev_has_treat, patient)={ edge_index=[2, 8538] },\n",
      "  (drug, rev_has_received, patient)={ edge_index=[2, 49262] }\n",
      ")\n",
      "\n",
      "Test data:\n",
      "================\n",
      "HeteroData(\n",
      "  patient={ node_id=[906] },\n",
      "  symptom={ node_id=[714] },\n",
      "  disease={ node_id=[2099] },\n",
      "  procedure={ node_id=[731] },\n",
      "  drug={ node_id=[178] },\n",
      "  (patient, presents, symptom)={\n",
      "    edge_index=[2, 32116],\n",
      "    edge_label=[0],\n",
      "    edge_label_index=[2, 0],\n",
      "  },\n",
      "  (patient, has, disease)={\n",
      "    edge_index=[2, 22069],\n",
      "    edge_label=[0],\n",
      "    edge_label_index=[2, 0],\n",
      "  },\n",
      "  (patient, has_treat, procedure)={\n",
      "    edge_index=[2, 8538],\n",
      "    edge_label=[0],\n",
      "    edge_label_index=[2, 0],\n",
      "  },\n",
      "  (patient, has_received, drug)={\n",
      "    edge_index=[2, 49262],\n",
      "    edge_label=[0],\n",
      "    edge_label_index=[2, 0],\n",
      "  },\n",
      "  (symptom, rev_presents, patient)={ edge_index=[2, 32116] },\n",
      "  (disease, rev_has, patient)={ edge_index=[2, 22069] },\n",
      "  (procedure, rev_has_treat, patient)={ edge_index=[2, 8538] },\n",
      "  (drug, rev_has_received, patient)={ edge_index=[2, 49262] }\n",
      ")\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\AR\\Desktop\\Tirocinio_Tesi\\MSc-Thesis-Project\\modelling_pyhealth.ipynb Cell 22\u001b[0m line \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/AR/Desktop/Tirocinio_Tesi/MSc-Thesis-Project/modelling_pyhealth.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyhealth\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m GNN\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/AR/Desktop/Tirocinio_Tesi/MSc-Thesis-Project/modelling_pyhealth.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m GNN(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/AR/Desktop/Tirocinio_Tesi/MSc-Thesis-Project/modelling_pyhealth.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     dataset\u001b[39m=\u001b[39;49mmimic3sample\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/AR/Desktop/Tirocinio_Tesi/MSc-Thesis-Project/modelling_pyhealth.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\Desktop\\Tirocinio_Tesi\\src\\pyhealth\\pyhealth\\models\\gnn.py:325\u001b[0m, in \u001b[0;36mGNN.__init__\u001b[1;34m(self, dataset, embedding_dim, hidden_dim, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m train_loader \u001b[39m=\u001b[39m LinkNeighborLoader(\n\u001b[0;32m    315\u001b[0m     data\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_data,\n\u001b[0;32m    316\u001b[0m     num_neighbors\u001b[39m=\u001b[39m[\u001b[39m20\u001b[39m, \u001b[39m10\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    321\u001b[0m     shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    322\u001b[0m )\n\u001b[0;32m    324\u001b[0m \u001b[39m# Inspect a sample:\u001b[39;00m\n\u001b[1;32m--> 325\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampled_data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(train_loader))\n\u001b[0;32m    327\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSampled mini-batch:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    328\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m===================\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\AR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\AR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\AR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\AR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\loader\\link_loader.py:201\u001b[0m, in \u001b[0;36mLinkLoader.collate_fn\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Samples a subgraph from a batch of input edges.\"\"\"\u001b[39;00m\n\u001b[0;32m    199\u001b[0m input_data: EdgeSamplerInput \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_data[index]\n\u001b[1;32m--> 201\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlink_sampler\u001b[39m.\u001b[39;49msample_from_edges(\n\u001b[0;32m    202\u001b[0m     input_data, neg_sampling\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mneg_sampling)\n\u001b[0;32m    204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_per_worker:  \u001b[39m# Execute `filter_fn` in the worker process\u001b[39;00m\n\u001b[0;32m    205\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_fn(out)\n",
      "File \u001b[1;32mc:\\Users\\AR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\sampler\\neighbor_sampler.py:258\u001b[0m, in \u001b[0;36mNeighborSampler.sample_from_edges\u001b[1;34m(self, inputs, neg_sampling)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msample_from_edges\u001b[39m(\n\u001b[0;32m    254\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    255\u001b[0m     inputs: EdgeSamplerInput,\n\u001b[0;32m    256\u001b[0m     neg_sampling: Optional[NegativeSampling] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    257\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[SamplerOutput, HeteroSamplerOutput]:\n\u001b[1;32m--> 258\u001b[0m     out \u001b[39m=\u001b[39m edge_sample(inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sample, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_nodes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdisjoint,\n\u001b[0;32m    259\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_time, neg_sampling)\n\u001b[0;32m    260\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubgraph_type \u001b[39m==\u001b[39m SubgraphType\u001b[39m.\u001b[39mbidirectional:\n\u001b[0;32m    261\u001b[0m         out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mto_bidirectional()\n",
      "File \u001b[1;32mc:\\Users\\AR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\sampler\\neighbor_sampler.py:627\u001b[0m, in \u001b[0;36medge_sample\u001b[1;34m(inputs, sample_fn, num_nodes, disjoint, node_time, neg_sampling)\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[39mif\u001b[39;00m edge_label_time \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# Always disjoint.\u001b[39;00m\n\u001b[0;32m    623\u001b[0m         seed_time_dict \u001b[39m=\u001b[39m {\n\u001b[0;32m    624\u001b[0m             input_type[\u001b[39m0\u001b[39m]: torch\u001b[39m.\u001b[39mcat([src_time, dst_time], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m),\n\u001b[0;32m    625\u001b[0m         }\n\u001b[1;32m--> 627\u001b[0m out \u001b[39m=\u001b[39m sample_fn(seed_dict, seed_time_dict)\n\u001b[0;32m    629\u001b[0m \u001b[39m# Enhance `out` by label information ##################################\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m disjoint:\n",
      "File \u001b[1;32mc:\\Users\\AR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\sampler\\neighbor_sampler.py:346\u001b[0m, in \u001b[0;36mNeighborSampler._sample\u001b[1;34m(self, seed, seed_time, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m     num_sampled_nodes \u001b[39m=\u001b[39m num_sampled_edges \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m requires \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    347\u001b[0m                       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meither \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpyg-lib\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch-sparse\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    349\u001b[0m \u001b[39mif\u001b[39;00m num_sampled_edges \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m     num_sampled_edges \u001b[39m=\u001b[39m remap_keys(\n\u001b[0;32m    351\u001b[0m         num_sampled_edges,\n\u001b[0;32m    352\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_edge_type,\n\u001b[0;32m    353\u001b[0m     )\n",
      "\u001b[1;31mImportError\u001b[0m: 'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'"
     ]
    }
   ],
   "source": [
    "from pyhealth.models import GNN\n",
    "\n",
    "model = GNN(\n",
    "    dataset=mimic3sample\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models\n",
    "\n",
    "Here we can use the models having the same input built in the previous cells. We tried GRASP, SafeDrug, Transformer, and so on. And evaluate them performance with several metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Transformer without symptoms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.models import Transformer\n",
    "\n",
    "model = Transformer(\n",
    "    dataset=mimic3sample,\n",
    "    feature_keys=[\"conditions\", \"procedures\"],\n",
    "    label_key=\"drugs\",\n",
    "    mode=\"multilabel\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Transformer with symptoms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.models import Transformer\n",
    "\n",
    "model_symptoms = Transformer(\n",
    "    dataset=mimic3sample,\n",
    "    feature_keys=[\"conditions\", \"procedures\", \"symptoms\"],\n",
    "    label_key=\"drugs\",\n",
    "    mode=\"multilabel\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Training without symptoms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(model=model)\n",
    "trainer.train(\n",
    "    model_name=\"transformer\",\n",
    "    train_dataloader=train_loader,\n",
    "    val_dataloader=val_loader,\n",
    "    epochs=5,\n",
    "    optimizer_params = {\"lr\": 2 * 1e-4},\n",
    "    monitor=\"pr_auc_samples\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Training with symptoms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.trainer import Trainer\n",
    "\n",
    "trainer_symptoms = Trainer(model=model_symptoms)\n",
    "trainer_symptoms.train(\n",
    "    model_name=\"transformer\",\n",
    "    train_dataloader=train_loader,\n",
    "    val_dataloader=val_loader,\n",
    "    epochs=5,\n",
    "    optimizer_params = {\"lr\": 2 * 1e-4},\n",
    "    monitor=\"pr_auc_samples\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Transformer Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 13/13 [00:00<00:00, 127.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8857151067559412,\n",
       " 'f1_samples': 0.5075168739925975,\n",
       " 'pr_auc_samples': 0.5948336401366011,\n",
       " 'jaccard_samples': 0.3466500940330525}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Without Symptoms - loss 0.3239 - time: 0m 6s\n",
    "from pyhealth.metrics import multilabel_metrics_fn\n",
    "\n",
    "y_true, y_prob, loss = trainer.inference(test_loader)\n",
    "metrics = [\"accuracy\", \"f1_samples\", \"pr_auc_samples\", \"jaccard_samples\"]\n",
    "multilabel_metrics_fn(y_true, y_prob, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 13/13 [00:00<00:00, 99.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8900255754475703,\n",
       " 'f1_samples': 0.5218895587506972,\n",
       " 'pr_auc_samples': 0.6142927508787751,\n",
       " 'jaccard_samples': 0.36047014930167576}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### With Symptoms - loss 0.3192 - time: 0m 9s\n",
    "from pyhealth.metrics import multilabel_metrics_fn\n",
    "\n",
    "y_true, y_prob, loss = trainer_symptoms.inference(test_loader)\n",
    "metrics = [\"accuracy\", \"f1_samples\", \"pr_auc_samples\", \"jaccard_samples\"]\n",
    "multilabel_metrics_fn(y_true, y_prob, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SafeDrug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- SafeDrug without symptoms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.models import SafeDrug\n",
    "\n",
    "model = SafeDrug(\n",
    "    dataset=mimic3sample\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- SafeDrug with symptoms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.models import SafeDrug_Mod\n",
    "\n",
    "model_symptoms = SafeDrug_Mod(\n",
    "    dataset=mimic3sample\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Training without symptoms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(model=model)\n",
    "trainer.train(\n",
    "    model_name=\"safedrug\",\n",
    "    train_dataloader=train_loader,\n",
    "    val_dataloader=val_loader,\n",
    "    epochs=5,\n",
    "    optimizer_params = {\"lr\": 2 * 1e-4},\n",
    "    monitor=\"pr_auc_samples\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Training with symptoms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.trainer import Trainer\n",
    "\n",
    "trainer_symptoms = Trainer(model=model_symptoms)\n",
    "trainer_symptoms.train(\n",
    "    model_name=\"safedrug\",\n",
    "    train_dataloader=train_loader,\n",
    "    val_dataloader=val_loader,\n",
    "    epochs=5,\n",
    "    optimizer_params = {\"lr\": 2 * 1e-4},\n",
    "    monitor=\"pr_auc_samples\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- SafeDrug Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 13/13 [00:03<00:00,  4.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8965200149429581,\n",
       " 'f1_samples': 0.4938840836868886,\n",
       " 'pr_auc_samples': 0.6566142176252147,\n",
       " 'jaccard_samples': 0.33422480694425677}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Without Symptoms - loss 0.2672 - time: 2m 6s\n",
    "from pyhealth.metrics import multilabel_metrics_fn\n",
    "\n",
    "y_true, y_prob, loss = trainer.inference(test_loader)\n",
    "metrics = [\"accuracy\", \"f1_samples\", \"pr_auc_samples\", \"jaccard_samples\"]\n",
    "multilabel_metrics_fn(y_true, y_prob, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 13/13 [00:03<00:00,  4.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8965487514009023,\n",
       " 'f1_samples': 0.4940201459077551,\n",
       " 'pr_auc_samples': 0.6575319724664682,\n",
       " 'jaccard_samples': 0.3343368918438221}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### With Symptoms - loss 0.2666 - time: 2m 0s\n",
    "from pyhealth.metrics import multilabel_metrics_fn\n",
    "\n",
    "y_true, y_prob, loss = trainer_symptoms.inference(test_loader)\n",
    "metrics = [\"accuracy\", \"f1_samples\", \"pr_auc_samples\", \"jaccard_samples\"]\n",
    "multilabel_metrics_fn(y_true, y_prob, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAMENet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRASP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RETAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MoleRec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizzazione Drug Recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_round = np.round(y_prob, 0)\n",
    "\n",
    "# Find the indices of the columns with values equal to 1 for each row\n",
    "column_indices = [np.where(row == 1)[0] for row in y_prob_round]\n",
    "\n",
    "indexes_prob=[]\n",
    "# Print the column indices for each row\n",
    "for i, indices in enumerate(column_indices):\n",
    "    indexes_prob.append(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty lists to store the recommended drugs, patient ids, and visit ids\n",
    "rec_drug = []\n",
    "patient_ids = []\n",
    "visit_ids = []\n",
    "\n",
    "# get the list of all drugs in the dataset\n",
    "list_drugs = mimic3sample.get_all_tokens('drugs')\n",
    "\n",
    "# iterate over the top indexes for each sample in test_ds\n",
    "for sample, top in zip(test_ds, indexes_prob):\n",
    "    \n",
    "    # append the patient id and visit id to their respective lists\n",
    "    patient_ids.append(sample['patient_id'])\n",
    "    visit_ids.append(sample['visit_id'])\n",
    "    \n",
    "    # create an empty list to store the recommended drugs for this sample\n",
    "    sample_rec_drug = []\n",
    "    \n",
    "    # iterate over the top indexes for this sample\n",
    "    for i in top:\n",
    "        \n",
    "        # append the drug at the i-th index to the recommended drugs list for this sample\n",
    "        sample_rec_drug.append(list_drugs[i])\n",
    "    \n",
    "    # append the recommended drugs for this sample to the recommended drugs list\n",
    "    rec_drug.append(sample_rec_drug)\n",
    "\n",
    "# create a dataframe with the patient ids, visit ids, and recommended drugs\n",
    "df_rec_drug = pd.DataFrame({'patient_id': patient_ids, 'visit_id': visit_ids, 'rec_drug': rec_drug})\n",
    "df_rec_drug.to_csv('data/rec_drug.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the indices of the columns with values equal to 1 for each row\n",
    "column_indices = [np.where(row == 1)[0] for row in y_true]\n",
    "\n",
    "indexes=[]\n",
    "# Print the column indices for each row\n",
    "for i, indices in enumerate(column_indices):\n",
    "    indexes.append(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty lists to store the recommended drugs, patient ids, and visit ids\n",
    "true_drug = []\n",
    "patient_ids = []\n",
    "visit_ids = []\n",
    "\n",
    "\n",
    "# get the list of all drugs in the dataset\n",
    "list_drugs = mimic3sample.get_all_tokens('drugs')\n",
    "\n",
    "# iterate over the top indexes for each sample in test_ds\n",
    "for sample, top in zip(test_ds, indexes):\n",
    "    \n",
    "    # append the patient id and visit id to their respective lists\n",
    "    patient_ids.append(sample['patient_id'])\n",
    "    visit_ids.append(sample['visit_id'])\n",
    "    \n",
    "    # create an empty list to store the recommended drugs for this sample\n",
    "    sample_true_drug = []\n",
    "    \n",
    "    # iterate over the top indexes for this sample\n",
    "    for i in top:\n",
    "        \n",
    "        # append the drug at the i-th index to the recommended drugs list for this sample\n",
    "        sample_true_drug.append(list_drugs[i])\n",
    "    \n",
    "    # append the recommended drugs for this sample to the recommended drugs list\n",
    "    true_drug.append(sample_true_drug)\n",
    "\n",
    "# create a dataframe with the patient ids, visit ids, and recommended drugs\n",
    "df_true_drug = pd.DataFrame({'patient_id': patient_ids, 'visit_id': visit_ids, 'true_drug': true_drug})\n",
    "df_true_drug.to_csv('data/true_drug.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A02B: DRUGS FOR PEPTIC ULCER AND GASTRO-OESOPHAGEAL REFLUX DISEASE (GORD)\n",
      "A06A: DRUGS FOR CONSTIPATION\n",
      "A12B: POTASSIUM SUPPLEMENTS\n",
      "A12C: OTHER MINERAL SUPPLEMENTS in ATC\n",
      "B01A: ANTITHROMBOTIC AGENTS\n",
      "B05X: I.V. SOLUTION ADDITIVES\n",
      "C03C: HIGH-CEILING DIURETICS\n",
      "C07A: BETA BLOCKING AGENTS\n",
      "N02A: OPIOID ANALGESICS\n",
      "N02B: OTHER ANALGESICS AND ANTIPYRETICS in ATC\n",
      "V04C: OTHER DIAGNOSTIC AGENTS in ATC\n",
      "V06D: OTHER NUTRIENTS in ATC\n"
     ]
    }
   ],
   "source": [
    "from pyhealth.medcode import InnerMap\n",
    "\n",
    "# initialize an InnerMap\n",
    "atc = InnerMap.load(\"ATC\")\n",
    "\n",
    "# select a patient from df_rec_drug\n",
    "patient_id = 25111\n",
    "visit_id = 147012\n",
    "patient_df = df_rec_drug[df_rec_drug['patient_id'].astype(int)==patient_id]\n",
    "patient_df = patient_df[patient_df['visit_id'].astype(int)==visit_id]\n",
    "\n",
    "# iterate over the recommended drugs for the selected patient\n",
    "for drugs in patient_df['rec_drug']:\n",
    "    # lookup the ATC code for each drug and print it\n",
    "    for drug in drugs:\n",
    "        print(f\"{drug}: {atc.lookup(drug)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
